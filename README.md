# llama-sbic

In the realm of complex task annotation, conventional methods often rely on human annotation, leading to potential biases and resource constraints. This study presents an innovative approach by fine-tuning Large Language Models on domain specific data as alternatives to manual annotation. Focusing on implied bias classification, a pivotal task in natural language understanding, the study explores the effectiveness of fine-tuned LLMs in generating annotations compared to baseline models. 

## Dataset

The research utilizes the Social Bias Inference Corpus (SBIC), a comprehensive dataset containing over 150,000 annotated social media posts covering biases against various demographic groups. This dataset captures a wide range of social biases, both subtle and overt, providing a robust foundation for training and evaluation.
